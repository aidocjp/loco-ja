+++
title = "Models"
description = ""
date = 2021-05-01T18:10:00+00:00
updated = 2024-01-07T21:10:00+00:00
draft = false
weight = 3
sort_by = "weight"
template = "docs/page.html"

[extra]
lead = ""
toc = true
top = false
flair =[]
+++


`loco`のモデルは、データベースのクエリと書き込みを簡単に行うためのエンティティクラスを意味しますが、マイグレーションやシーディングも含みます。

## Sqlite vs Postgres 

新しいアプリを作成するときにデフォルトである`sqlite`を選択した可能性があります。Locoは`sqlite`と`postgres`間で_シームレス_に移行することができます。

開発には`sqlite`を使用し、本番には`postgres`を使用するのが一般的です。`pg`固有の機能を使用するため、開発と本番の両方で`postgres`を一貫して好む人もいます。最近では本番でも`sqlite`を使用する人もいます。いずれにしても、すべて有効な選択です。

`sqlite`の代わりに`postgres`を設定するには、`config/development.yaml`（または`production.yaml`）に移動し、アプリ名が`myapp`であると仮定して、以下を設定します：

```yaml
database:
  uri: "{{ get_env(name="DATABASE_URL", default="postgres://loco:loco@localhost:5432/myapp_development") }"
```

<div class="infobox">
Your local postgres database should be with <code>loco:loco</code> and a db named <code>myapp_development</code>. For test and production, your DB should be named <code>myapp_test</code> and <code>myapp_production</code> respectively.
</div>

便宜上、PostgreSQLデータベースサーバーを起動するdockerコマンドを以下に示します：

<!-- <snip id="postgres-run-docker-command" inject_from="yaml" template="sh"> -->
```sh
docker run -d -p 5432:5432 \
  -e POSTGRES_USER=loco \
  -e POSTGRES_DB=myapp_development \
  -e POSTGRES_PASSWORD="loco" \
  postgres:15.3-alpine
```
<!-- </snip> -->



最後に、doctorコマンドを使用して接続を検証することもできます：

<!-- <snip id="doctor-command" inject_from="yaml template="sh"> -->
```sh
$ cargo loco doctor
    Finished dev [unoptimized + debuginfo] target(s) in 0.32s
    Running `target/debug/myapp-cli doctor`
✅ SeaORM CLI is installed
✅ DB connection: success
✅ Redis connection: success
```
<!-- </snip> -->

## Fat models, slim controllers

`loco`のモデルは**active recordに倣って設計されています**。これは、モデルがあなたの世界の中心点であり、アプリが持つすべてのロジックや操作がそこにあるべきことを意味します。

これは`User::create`がユーザーを作成することを意味しますが、**同時に**`user.buy(product)`が商品を購入することも意味します。

この方向性に同意する場合、以下のメリットを無料で得ることができます：

- **時間効率的なテスト**：モデルをテストすることで、ロジックと可動部分のほとんど、またはすべてをテストできるため。
- **_タスク_、ワーカー、その他の場所から**完全なアプリワークフローを実行する能力。
- モデルを組み合わせることで、機能とユースケースを効果的に**組み合わせる**ことができ、他には何も必要ありません。
- 本質的に、**モデルがあなたのアプリになり**、コントローラーはアプリを世界に公開する単なる一つの方法です。

ActiveRecord抽象化の背後にあるメインのORMとして[`SeaORM`](https://www.sea-ql.org/SeaORM/)を使用しています。

- _なぜDieselではないのか？_ - Dieselはより優れたパフォーマンスを持っていますが、そのマクロと一般的なアプローチは、私たちが実現しようとしていることと互換性がないと感じました
- _なぜsqlxではないのか_ - SeaORMは内部でsqlxを使用しているため、必要に応じて生の`sqlx`を使用するための配管はそこにあります。

## Example model

`loco`モデルのライフサイクルは_migration_から始まり、その後データベース構造から_entity_ Rustコードが自動的に生成されます：

```
src/
  models/
    _entities/   <--- autogenerated code
      users.rs   <--- the bare entity and helper traits
    users.rs  <--- your custom activerecord code
```

`users` activerecordの使用は、SeaORMで使用するのと同じです[例はこちらを参照](https://www.sea-ql.org/SeaORM/docs/next/basic-crud/select/)

`users` activerecordに機能を追加するには_拡張_を使用します：

```rust
impl super::_entities::users::ActiveModel {
    /// .
    ///
    /// # Errors
    ///
    /// .
    pub fn foobar(&self) -> Result<(), DbErr> {
        // implement and get back a `user.foobar()`
    }
}
```

# Crafting models

## The model generator

新しいモデルを追加するために、モデルジェネレーターはマイグレーションを作成し、それを実行し、その後データベーススキーマからエンティティ同期をトリガーして、モデルエンティティを作成し構築します。

```
$ cargo loco generate model posts title:string! content:text user:references
```

マイグレーション経由でモデルが追加されると、以下のデフォルトフィールドが提供されます：

- `created_at` (ts!): これはモデルが作成された時刻を示すタイムスタンプです。
- `updated_at` (ts!): これはモデルが更新された時刻を示すタイムスタンプです。

これらのフィールドは、マイグレーションコマンドで提供した場合は無視されます。

### Field syntax

各フィールドタイプには`!`または`^`のサフィックスを含めることができます：

- `!`はフィールドが**必須**であることを示します（つまり、データベースで`NOT NULL`）
- `^`はフィールドが**ユニーク**でなければならないことを示します。

サフィックスが使用されない場合、フィールドはnullにできます。


### Data types

スキーマデータタイプについて、スキーマを理解するために以下のマッピングを使用できます：

```rust
("uuid^", "uuid_uniq"),
("uuid", "uuid_null"),
("uuid!", "uuid"),
("string", "string_null"),
("string!", "string"),
("string^", "string_uniq"),
("text", "text_null"),
("text!", "text"),
("text^", "text_uniq"),
("small_unsigned^", "small_unsigned_uniq"),
("small_unsigned", "small_unsigned_null"),
("small_unsigned!", "small_unsigned"),
("big_unsigned^", "big_unsigned"),
("big_unsigned", "big_unsigned_null"),
("big_unsigned!", "big_unsigned_uniq"),
("small_int", "small_integer_null"),
("small_int!", "small_integer"),
("small_int^", "small_integer_uniq"),
("int", "integer_null"),
("int!", "integer"),
("int^", "integer_uniq"),
("big_int", "big_integer_null"),
("big_int!", "big_integer"),
("big_int^", "big_integer_uniq"),
("float", "float_null"),
("float!", "float"),
("float^", "float_uniq"),
("double", "double_null"),
("double!", "double"),
("double^", "double_uniq"),
("decimal", "decimal_null"),
("decimal!", "decimal"),
("decimal_len", "decimal_len_null"),
("decimal_len!", "decimal_len"),
("decimal^", "decimal_uniq"),
("bool", "boolean_null"),
("bool!", "boolean"),
("tstz", "timestamp_with_time_zone_null"),
("tstz!", "timestamp_with_time_zone"),
("date", "date_null"),
("date!", "date"),
("date^", "date_uniq"),
("date_time", "date_time_null"),
("date_time!", "date_time"),
("date_time^", "date_time_uniq"),
("blob", "blob_null"),
("blob!", "blob"),
("blob^", "blob_uniq"),
("json", "json_null"),
("json!", "json"),
("jsonb", "json_binary_null"),
("jsonb!", "json_binary"),
("jsonb^", "jsonb_uniq"),
("money", "money_null"),
("money!", "money"),
("money^", "money_uniq"),
("unsigned", "unsigned_null"),
("unsigned!", "unsigned"),
("unsigned^", "unsigned_uniq"),
("binary_len", "binary_len_null"),
("binary_len!", "binary_len"),
("binary_len^", "binary_len_uniq"),
("var_binary", "var_binary_null"),
("var_binary!", "var_binary"),
(" array", "array"),
(" array!", "array"),
(" array^", "array"),
```

Locoは、生成されるモデルと参照したいモデルの間の外部キー関係を定義するために`references`タイプを使用します。ただし、この特別なタイプを使用する方法は2つあることに注意してください：

1. `<other_model>:references`
2. `<other_model>:references:<column_name>`

最初のもの（`<other_model>:references`）は、セマンティクスから既に明らかなように、既存のモデル（この場合は`other_model`）への外部キー関係を作成するために使用されます。ただし、**フィールド名は暗黙的**です。

例えば、`post`という名前の新しいモデルを作成し、既に存在する`users`テーブル（マイグレーションが適用された新しいlocoプロジェクト内）を参照するフィールド/カラムを持たせたい場合、以下のコマンドを使用します：

```
cargo loco g model post title:string user:references
```

`user:references`を使用すると、特別な`<other_model>:references`タイプを使用し、`post`（新しいモデル）と`user`（既存のモデル）の間に関係を作成し、`posts`テーブルに`user_id`（暗黙的フィールド名）参照フィールドを追加します。

一方、2番目のアプローチ（`<other_model>:references:<column_name>`）を使用すると、好みに応じてフィールド/カラムに名前を付けることができる贅沢を得られます。したがって、前の例を取り上げて、タイトルとおそらく著者を指す外部キーを持つ`post`テーブルを作成したい場合、同じ前のコマンドを使用しますが、少し変更します：

```
cargo loco g model post title:string user:references:authored_by
```

`user:references:authored_by`を使用すると、特別な`<other_model>:references:<column_name>`タイプを使用し、`post`と`user`の間に関係を作成し、`user_id`の代わりに`authored_by`（明示的フィールド名）参照フィールドを`posts`テーブルに追加します。

空のモデルを生成できます：

```
$ cargo loco generate model posts
```


または、参照のないデータモデル：

```
$ cargo loco generate model posts title:string! content:text
```

## Migrations

モデルジェネレーターを使用する以外に、*マイグレーションを作成*することでスキーマを駆動します。

```
$ cargo loco generate migration <name of migration> [name:type, name:type ...]
```

これはプロジェクトのルートの`migration/`にマイグレーションを作成します。

適用できます：

```
$ cargo loco db migrate
```

そしてそこからエンティティ（Rustコード）を生成し直します：

```
$ cargo loco db entities
```

LocoはRailsと同様にマイグレーションファーストのフレームワークです。これは、モデル、データフィールド、またはモデル指向の変更を追加したいときに、それを説明するマイグレーションから始め、その後マイグレーションを適用して`model/_entities`で生成されたエンティティを取得することを意味します。

これは_everything-as-code_、_再現性_、_原子性_を強制し、スキーマの知識が失われることがありません。 

**マイグレーションの命名は重要**で、生成されるマイグレーションのタイプはマイグレーション名から推測されます。

### 新しいテーブルを作成

* 名前テンプレート: `Create___`
* 例: `CreatePosts`

```
$ cargo loco g migration CreatePosts title:string content:string
```

### カラムを追加

* 名前テンプレート: `Add___To___`
* 例: `AddNameAndAgeToUsers`（文字列`NameAndAge`は関係ありません、カラムは個別に指定しますが、`Users`はテーブル名になるため重要です）

```
$ cargo loco g migration AddNameAndAgeToUsers name:string age:int
```

### カラムを削除

* 名前テンプレート: `Remove___From___`
* 例: `RemoveNameAndAgeFromUsers`（_カラム追加_と同じ注意があります）

```
$ cargo logo g migration RemoveNameAndAgeFromUsers name:string age:int
```

### 参照を追加

* 名前テンプレート: `Add___RefTo___`
* 例: `AddUserRefToPosts`（`User`は関係ありません、参照は個別に1つまたは複数指定します。`Posts`はマイグレーションでテーブル名になるため重要です）

```
$ cargo loco g migration AddUserRefToPosts user:references
```

### 結合テーブルを作成

* 名前テンプレート: `CreateJoinTable___And___`（2つのテーブル間でサポート）
* 例: `CreateJoinTableUsersAndGroups`

```
$ cargo loco g migration CreateJoinTableUsersAndGroups count:int
```

関係に関するいくつかの状態カラム（ここでは`count`など）を追加することもできます。

### 空のマイグレーションを作成

上記のパターンのいずれにも当てはまらないマイグレーションには、説明的な名前を使用して空のマイグレーションを作成します。

```
$ cargo loco g migration FixUsersTable
```

### Down Migrations

If you realize that you made a mistake, you can always undo the migration. This will undo the changes made by the migration (assuming that you added the appropriate code for `down` in the migration).

<!-- <snip id="migrate-down-command" inject_from="yaml" template="sh"> -->
```sh
cargo loco db down
```
<!-- </snip> -->

The `down` command on its own will rollback only the last migration. If you want to rollback multiple migrations, you can specify the number of migrations to rollback.

<!-- <snip id="migrate-down-n-command" inject_from="yaml" template="sh"> -->
```sh
cargo loco db down 2
```
<!-- </snip> -->

### Verbs, singular and plural

- **references**: use **singular** for the table name, and a `<other_model>:references` type. `user:references` (references `Users`), `vote:references` (references `Votes`). `<other_model>:references:<column_name>` is also available `train:references:departing_train` (references `Trains`).
- **column names**: anything you like. Prefer `snake_case`.
- **table names**: **plural, snake case**. `users`, `draft_posts`.
- **migration names**: anything that can be a file name, prefer snake case. `create_table_users`, `add_vote_id_to_movies`.
- **model names**: generated automatically for you. Usually the generated name is pascal case, plural. `Users`, `UsersVotes`.

Here are some examples showcasing the naming conventions:

```sh
$ cargo loco generate model movies long_title:string user:references:added_by director:references
```

- model name in plural: `movies`
- reference director is in singular: `director:references`
- reference added_by is an explicit name in singular, the referenced model remains singular: `user:references:added_by`
- column name in snake case: `long_title:string`

### Authoring migrations

To use the migrations DSL, make sure you have the following `loco_rs::schema::*` import and SeaORM `prelude`.

```rust
use loco_rs::schema::*;
use sea_orm_migration::prelude::*;
```

Then, create a struct:

```rust
#[derive(DeriveMigrationName)]
pub struct Migration;
```

And then implement your migration (see below).

**Create a table**

Create a table, provide two arrays: (1) columns (2) references.

Leave references empty to not create any reference fields.

```rust
impl MigrationTrait for Migration {
    async fn up(&self, m: &SchemaManager) -> Result<(), DbErr> {
        create_table(
            m,
            "posts",
            &[
                ("title", ColType::StringNull),
                ("content", ColType::StringNull),
            ],
            &[],
        )
        .await
    }

    async fn down(&self, m: &SchemaManager) -> Result<(), DbErr> {
        drop_table(m, "posts").await
    }
}
```

**Create a join table**

Provide the references to the second array argument. Use an empty string `""` to indicate you want us to generate a reference column name for you (e.g. a `user` reference will imply connecting the `users` table through a `user_id` column in `group_users`).

Provide a non-empty string to indicate a specific name for the reference column name.

```rust
impl MigrationTrait for Migration {
    async fn up(&self, m: &SchemaManager) -> Result<(), DbErr> {
        create_join_table(m, "group_users", &[], &[("user", ""), ("group", "")]).await
    }

    async fn down(&self, m: &SchemaManager) -> Result<(), DbErr> {
        drop_table(m, "group_users").await
    }
}
```

**Add a column**

Add a single column. You can use as many such statements as you like in a single migration (to add multiple columns).


```rust
impl MigrationTrait for Migration {
    async fn up(&self, m: &SchemaManager) -> Result<(), DbErr> {
        add_column(m, "users", "amount", ColType::DecimalLenNull(24,8)).await?;
        Ok(())
    }

    async fn down(&self, m: &SchemaManager) -> Result<(), DbErr> {
        remove_column(m, "users", "amount").await?;
        Ok(())
    }
}
```


### Authoring advanced migrations

Using the `manager` directly lets you access more advanced operations while authoring your migrations.

**Add a column**

```rust
  manager
    .alter_table(
        Table::alter()
            .table(Movies::Table)
            .add_column_if_not_exists(integer(Movies::Rating))
            .to_owned(),
    )
    .await
```

**Drop a column**

```rust
  manager
    .alter_table(
        Table::alter()
            .table(Movies::Table)
            .drop_column(Movies::Rating)
            .to_owned(),
    )
    .await
```

**Add index**

You can copy some of this code for adding an index

```rust
  manager
    .create_index(
        Index::create()
            .name("idx-movies-rating")
            .table(Movies::Table)
            .col(Movies::Rating)
            .to_owned(),
    )
    .await;
```

**Create a data fix**

Creating a data fix in a migration is easy - just use SQL statements as you like:

```rust
  async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {

    let db = manager.get_connection();
    
    // issue SQL queries with `db`
    // https://www.sea-ql.org/SeaORM/docs/basic-crud/raw-sql/#use-raw-query--execute-interface

    Ok(())
  }
```

Having said that, it's up to you to code your data fixes in:

* `task` - where you can use high level models
* `migration` - where you can both change structure and fix data stemming from it with raw SQL
* or an ad-hoc `playground` - where you can use high level models or experiment with things


## Validation

We use the [validator](https://docs.rs/validator) library under the hood. First, build your validator with the constraints you need, and then implement `Validatable` for your `ActiveModel`.


<!-- <snip id="model-validation" inject_from="code" template="rust"> -->
```rust
#[derive(Debug, Validate, Deserialize)]
pub struct Validator {
    #[validate(length(min = 2, message = "Name must be at least 2 characters long."))]
    pub name: String,
    #[validate(email(message = "invalid email"))]
    pub email: String,
}

impl Validatable for super::_entities::users::ActiveModel {
    fn validator(&self) -> Box<dyn Validate> {
        Box::new(Validator {
            name: self.name.as_ref().to_owned(),
            email: self.email.as_ref().to_owned(),
        })
    }
}
```
<!-- </snip> -->


Note that `Validatable` is how you instruct Loco which `Validator` to provide and how to build it from a model.

Now you can use `user.validate()` seamlessly in your code, when it is `Ok` the model is valid, otherwise you'll find validation errors in `Err(...)` available for inspection.


## Relationships

### One to many

Here is how to associate a `Company` with an existing `User` model.

```
$ cargo loco generate model company name:string user:references
```

This will create a migration with a `user_id` field in `Company` which will reference a `User`.


### Many to many

Here is how to create a typical "votes" table, which links a `User` and a `Movie` with a many-to-many link table. Note that it uses the special `--link` flag in the model generator.

Let's create a new `Movie` entity:

```
$ cargo loco generate model movies title:string
```

And now the link table between `User` (which we already have) and `Movie` (which we just generated) to record votes:

```
$ cargo loco generate model --link users_votes user:references movie:references vote:int
    ..
    ..
Writing src/models/_entities/movies.rs
Writing src/models/_entities/users.rs
Writing src/models/_entities/mod.rs
Writing src/models/_entities/prelude.rs
... Done.
```

This will create a many-to-many link table named `UsersVotes` with a composite primary key containing both `user_id` and `movie_id`. Because it has precisely 2 IDs, SeaORM will identify it as a many-to-many link table, and generate entities with the appropriate `via()` relationship:


```rust
// User, newly generated entity with a `via` relation at _entities/users.rs

// ..
impl Related<super::movies::Entity> for Entity {
    fn to() -> RelationDef {
        super::users_votes::Relation::Movies.def()
    }
    fn via() -> Option<RelationDef> {
        Some(super::users_votes::Relation::Users.def().rev())
    }
}
```

Using `via()` will cause `find_related` to walk through the link table without you needing to know the details of the link table.




## Configuration

Model configuration that's available to you is exciting because it controls all aspects of development, testing, and production, with a ton of goodies, coming from production experience.

<!-- <snip id="configuration-database" inject_from="code" template="yaml"> -->
```yaml
database:
  # Database connection URI
  uri: {{get_env(name="DATABASE_URL", default="postgres://loco:loco@localhost:5432/loco_app")}}
  # When enabled, the sql query will be logged.
  enable_logging: false
  # Set the timeout duration when acquiring a connection.
  connect_timeout: 500
  # Set the idle duration before closing a connection.
  idle_timeout: 500
  # Minimum number of connections for a pool.
  min_connections: 1
  # Maximum number of connections for a pool.
  max_connections: 1
  # Run migration up when application loaded
  auto_migrate: true
  # Truncate database when application loaded. This is a dangerous operation, make sure that you using this flag only on dev environments or test mode
  dangerously_truncate: false
  # Recreating schema when application loaded.  This is a dangerous operation, make sure that you using this flag only on dev environments or test mode
  dangerously_recreate: false
```
<!-- </snip>-->


By combining these flags, you can create different experiences to help you be more productive.

You can truncate before an app starts -- which is useful for running tests, or you can recreate the entire DB when the app starts -- which is useful for integration tests or setting up a new environment. In production, you want these turned off (hence the "dangerously" part).

# Seeding

`Loco` comes equipped with a convenient `seeds` feature, streamlining the process for quick and easy database reloading. This functionality proves especially invaluable during frequent resets in development and test environments. Let's explore how to get started with this feature:

## Creating a new seed

### 1. Creating a new seed file

Navigate to `src/fixtures` and create a new seed file. For instance:

```
src/
  fixtures/
    users.yaml
```

In this yaml file, enlist a set of database records for insertion. Each record should encompass the mandatory database fields, based on your database constraints. Optional values are at your discretion. Suppose you have a database DDL like this:

```sql
CREATE TABLE public.users (
	id serial4 NOT NULL,
	email varchar NOT NULL,
	"password" varchar NOT NULL,
	reset_token varchar NULL,
	created_at timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
	CONSTRAINT users_email_key UNIQUE (email),
	CONSTRAINT users_pkey PRIMARY KEY (id)
);
```

The mandatory fields include `id`, `password`, `email`, and `created_at`. The reset token can be left empty. Your migration content file should resemble the following:

```yaml
---
- id: 1
  email: user1@example.com
  password: "$2b$12$gf4o2FShIahg/GY6YkK2wOcs8w4.lu444wP6BL3FyjX0GsxnEV6ZW"
  created_at: "2023-11-12T12:34:56.789"
- id: 2
  pid: 22222222-2222-2222-2222-222222222222
  email: user2@example.com
  reset_token: "SJndjh2389hNJKnJI90U32NKJ"
  password: "$2b$12$gf4o2FShIahg/GY6YkK2wOcs8w4.lu444wP6BL3FyjX0GsxnEV6ZW"
  created_at: "2023-11-12T12:34:56.789"
```

### Connect the seed

Integrate your seed into the app's Hook implementations by following these steps:

1. Navigate to your app's Hook implementations.
2. Add the seed within the seed function implementation. Here's an example in Rust:

```rs
impl Hooks for App {
    // Other implementations...

    async fn seed(ctx: &AppContext, base: &Path) -> Result<()> {
        db::seed::<users::ActiveModel>(&ctx.db, &base.join("users.yaml").display().to_string()).await?;
        Ok(())
    }
}

```

This implementation ensures that the seed is executed when the seed function is called. Adjust the specifics based on your application's structure and requirements.

## Managing Seed via CLI

- **Reset the Database**  
  Clear all existing data before importing seed files. This is useful when you want to start with a fresh database state, ensuring no old data remains.
- **Dump Database Tables to Files**  
  Export the contents of your database tables to files. This feature allows you to back up the current state of your database or prepare data for reuse across environments.

To access the seed commands, use the following CLI structure:
<!-- <snip id="seed-help-command" inject_from="yaml" action="exec" template="sh"> -->
```sh
Seed your database with initial data or dump tables to files

Usage: demo_app-cli db seed [OPTIONS]

Options:
  -r, --reset                      Clears all data in the database before seeding
  -d, --dump                       Dumps all database tables to files
      --dump-tables <DUMP_TABLES>  Specifies specific tables to dump
      --from <FROM>                Specifies the folder containing seed files (defaults to 'src/fixtures') [default: src/fixtures]
  -e, --environment <ENVIRONMENT>  Specify the environment [default: development]
  -h, --help                       Print help
  -V, --version                    Print version
```
<!-- </snip> -->


### Using a Test

1. Enable the testing feature (`testing`)

2. In your test section, follow the example below:

```rust
use loco_rs::testing::prelude::*;

#[tokio::test]
#[serial]
async fn handle_create_with_password_with_duplicate() {

    let boot = boot_test::<App, Migrator>().await;
    seed::<App>(&boot.app_context).await.unwrap();
    assert!(get_user_by_id(1).ok());
}
```

# Multi-DB

`Loco` enables you to work with more than one database and share instances across your application.

## Extra DB

To set up an additional database, begin with database connections and configuration. The recommended approach is to navigate to your configuration file and add the following under [settings](@/docs/the-app/your-project.md#settings):

```yaml
settings:
  extra_db:
    uri: postgres://loco:loco@localhost:5432/loco_app
    enable_logging: false
    connect_timeout: 500
    idle_timeout: 500
    min_connections: 1
    max_connections: 1
    auto_migrate: true
    dangerously_truncate: false
    dangerously_recreate: false
```



Load this [initializer](@/docs/extras/pluggability.md#initializers) into `initializers` hook like this example

```rs
async fn initializers(ctx: &AppContext) -> Result<Vec<Box<dyn Initializer>>> {
        let  initializers: Vec<Box<dyn Initializer>> = vec![
            Box::new(loco_rs::initializers::extra_db::ExtraDbInitializer),
        ];

        Ok(initializers)
    }
```

Now, you can use the secondary database in your controller:

```rust
use sea_orm::DatabaseConnection;
use axum::{response::IntoResponse, Extension};

pub async fn list(
    State(ctx): State<AppContext>,
    Extension(secondary_db): Extension<DatabaseConnection>,
) -> Result<impl IntoResponse> {
  let res = Entity::find().all(&secondary_db).await;
}
```

## Multi-DB (multi-tenant)

To connect more than two different databases, the database configuration should look like this:
```yaml
settings:
  multi_db: 
    secondary_db:      
      uri: postgres://loco:loco@localhost:5432/loco_app
      enable_logging: false      
      connect_timeout: 500      
      idle_timeout: 500      
      min_connections: 1      
      max_connections: 1      
      auto_migrate: true      
      dangerously_truncate: false      
      dangerously_recreate: false
    third_db:      
      uri: postgres://loco:loco@localhost:5432/loco_app
      enable_logging: false      
      connect_timeout: 500      
      idle_timeout: 500      
      min_connections: 1      
      max_connections: 1      
      auto_migrate: true      
      dangerously_truncate: false      
      dangerously_recreate: false
```

Next load this [initializer](@/docs/extras/pluggability.md#initializers) into `initializers` hook like this example

```rs
async fn initializers(ctx: &AppContext) -> Result<Vec<Box<dyn Initializer>>> {
        let  initializers: Vec<Box<dyn Initializer>> = vec![
            Box::new(loco_rs::initializers::multi_db::MultiDbInitializer),
        ];

        Ok(initializers)
    }
```

Now, you can use the multiple databases in your controller:

```rust
use sea_orm::DatabaseConnection;
use axum::{response::IntoResponse, Extension};
use loco_rs::db::MultiDb;

pub async fn list(
    State(ctx): State<AppContext>,
    Extension(multi_db): Extension<MultiDb>,
) -> Result<impl IntoResponse> {
  let third_db = multi_db.get("third_db")?;
  let res = Entity::find().all(third_db).await;
}
```

# Testing

If you used the generator to crate a model migration, you should also have an auto generated model test in `tests/models/posts.rs` (remember we generated a model named `post`?)

A typical test contains everything you need to set up test data, boot the app, and reset the database automatically before the testing code runs. It looks like this:

```rust
use loco_rs::testing::prelude::*;

#[tokio::test]
#[serial]
async fn can_find_by_pid() {
    configure_insta!();

    let boot = boot_test::<App, Migrator>().await;
    seed::<App>(&boot.app_context).await.unwrap();

    let existing_user =
        Model::find_by_pid(&boot.app_context.db, "11111111-1111-1111-1111-111111111111").await;
    let non_existing_user_results =
        Model::find_by_email(&boot.app_context.db, "23232323-2323-2323-2323-232323232323").await;

    assert_debug_snapshot!(existing_user);
    assert_debug_snapshot!(non_existing_user_results);
}
```



To simplify the testing process, `Loco` provides helpful functions that make writing tests more convenient. Ensure you enable the testing feature in your `Cargo.toml`:

```toml
[dev-dependencies]
loco-rs = { version = "*",  features = ["testing"] }
```


## Database cleanup

In some cases, you may want to run tests with a clean dataset, ensuring that each test is independent of others and not affected by previous data. To enable this feature, modify the `dangerously_truncate` option to true in the `config/test.yaml` file under the database section. This setting ensures that Loco truncates all data before each test that implements the boot app.

> ⚠️ Caution: Be cautious when using this feature to avoid unintentional data loss, especially in a production environment.

- When doing it recommended to run all the relevant task in with [serial](https://crates.io/crates/rstest) crate.
- To decide which tables you want to truncate, add the entity model to the App hook:


```rust
pub struct App;
#[async_trait]
impl Hooks for App {
    //...
    async fn truncate(ctx: &AppContext) -> Result<()> {
        // truncate_table(&ctx.db, users::Entity).await?;
        Ok(())
    }

}
```

## Async
When writing async tests with database data, it's important to ensure that one test does not affect the data used by other tests. Since async tests can run concurrently on the same database dataset, this can lead to unstable test results.

Instead of using `boot_test`, as described in the documentation for synchronous tests, use the `boot_test_with_create_db` function. This function generates a random database schema name and ensures that the tables are deleted once the test is completed.

Note: If you cancel the test run midway (e.g., by pressing `Ctrl + C`), the cleanup process will not execute, and the database tables will remain. In such cases, you will need to manually remove them.

```rust
use loco_rs::testing::prelude::*;

#[tokio::test]
async fn boot_test_with_create_db() {
    let boot = boot_test_with_create_db::<App, Migrator>().await;
}
```

## Seeding

```rust
use loco_rs::testing::prelude::*;

#[tokio::test]
#[serial]
async fn is_user_exists() {
    configure_insta!();

    let boot = boot_test::<App, Migrator>().await;
    seed::<App>(&boot.app_context).await.unwrap();
    assert!(get_user_by_id(1).ok());

}
```

This documentation provides an in-depth guide on leveraging Loco's testing helpers, covering database cleanup, data cleanup for snapshot testing, and seeding data for tests.

## Snapshot test data cleanup

Snapshot testing often involves comparing data structures with dynamic fields such as `created_date`, `id`, `pid`, etc. To ensure consistent snapshots, Loco defines a list of constant data with regex replacements. These replacements can replace dynamic data with placeholders.

Example using [insta](https://crates.io/crates/insta) for snapshots.

in the following example you can use `cleanup_user_model` which clean all user model data.

```rust
use loco_rs::testing::prelude::*;

#[tokio::test]
#[serial]
async fn can_create_user() {
    request::<App, Migrator, _, _>(|request, _ctx| async move {
        // create user test
        with_settings!({
            filters => cleanup_user_model()
        }, {
            assert_debug_snapshot!(current_user_request.text());
        });
    })
    .await;
}

```

You can also use cleanup constants directly, starting with `CLEANUP_`.

## Customizing Entity Generation

You can customize how `sea-orm-cli` generates entities by adding configuration to your `Cargo.toml` under the `[package.metadata.db.entity]` section. For example:

```toml
[package.metadata.db.entity]
max-connections = 1
ignore-tables = "table1,table2"
model-extra-derives = "CustomDerive"
```

This configuration will be passed as flags to `sea-orm-cli generate entity` when running `cargo loco db entities`.

Note that some flags like `--output-dir` and `--database-url` cannot be overridden as they are managed by Loco.
